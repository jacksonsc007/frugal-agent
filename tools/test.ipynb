{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1]]\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    [0],\n",
    "    [1]\n",
    "]\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'foo'], [1, 'foo']]\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    [0],\n",
    "    [1]\n",
    "]\n",
    "print(prompt)\n",
    "def foo(prompt):\n",
    "    for p in prompt:\n",
    "        p. append(\"foo\")\n",
    "foo(prompt)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0], [1])\n",
      "([0, 'foo'], [1, 'foo'])\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    [0],\n",
    "    [1]\n",
    ")\n",
    "print(prompt)\n",
    "def foo(prompt):\n",
    "    for p in prompt:\n",
    "        p. append(\"foo\")\n",
    "foo(prompt)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1]]\n",
      "[[0, 'foo'], [1, 'foo']]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "prompt = [[0], [1]]\n",
    "new_prompt = copy.deepcopy(prompt)  # Creates a new independent copy\n",
    "\n",
    "foo(new_prompt)  # Modifies only 'new_prompt'\n",
    "print(prompt)  # Output: [[0], [1]]\n",
    "print(new_prompt)  # Output: [[0, \"foo\"], [1, \"foo\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call': 'true'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    \"tool_call\": \"true\"\n",
    "}\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'tool_call': 'true'}\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': '{\"a\": 1}'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    \"args\": '{\"a\": 1}'\n",
    "}\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': '{\"a\": 1}'}\n"
     ]
    }
   ],
   "source": [
    "def foo(d1):\n",
    "    print(d1)\n",
    "foo(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['name1', 'name2']\n",
    "b = ['name1', 'name2']\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.remove('name1')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name1', 'name2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [1, 1]\n",
    "c == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmean\u001b[49m([torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m2\u001b[39m)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "mean([torch.tensor(1), torch.tensor(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '':\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if 'a':\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0', '1', '0', '1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    '1' if i % 2 == 0 else '0' for i in range(5) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a =[1,2,3]\n",
    "a = torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.expand(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs/text.md'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "a = 'outputs'\n",
    "b = 'text.md'\n",
    "os.path.join(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"OUTPUT_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "pseudo_loss = torch.tensor(0.0, requires_grad=True)\n",
    "pseudo_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_loss.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you are a mastermind overseeing a suite of advanced AI tools designed to assist users with various tasks.\n",
      "You should consider the user's request and decide which tool you would call upon to provide the best response.\n",
      "If the user does not explicitly specify arguments of tools, you should deduce it from the context.\n",
      "For instance, the default file type for the tool 'save_file' is markdown. Besides, when you decides to call 'sav_file' tool to save the formatted content, you should pass the entire intact formatted content to it.\n"
     ]
    }
   ],
   "source": [
    "MASTERMIND_SYS_PROMPT_TOOL_SPECIFIC = \"\"\"\\\n",
    "Imagine you are a mastermind overseeing a suite of advanced AI tools designed to assist users with various tasks.\n",
    "You should consider the user's request and decide which tool you would call upon to provide the best response.\n",
    "If the user does not explicitly specify arguments of tools, you should deduce it from the context.\n",
    "For instance, the default file type for the tool 'save_file' is markdown. Besides, when you decides to call 'sav_file' tool to save the formatted content, you should pass the entire intact formatted content to it.\\\n",
    "\"\"\"\n",
    "print(MASTERMIND_SYS_PROMPT_TOOL_SPECIFIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response =\"\"\"<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"discussion_on_middle_aged_mental_health.md\", \"content\": \"---\n",
    "tags:\n",
    "  - {health} health/mental_health\n",
    "  - {age} age/middle_aged\n",
    "---\n",
    "\n",
    "# Instruction\n",
    "Discuss recent news article about study finding that middle-aged people are more likely to suffer from mental health issues.\n",
    "\n",
    "# Summary\n",
    "A conversation about a recent study indicating that middle-aged individuals are more likely to experience mental health issues, discussing potential reasons and the importance of mental health awareness.\n",
    "\n",
    "## Details\n",
    "Person 1: Hey, did you read that article in the news today about mental health?  \n",
    "Person 2: No, I didn't. What was it about?  \n",
    "Person 1: It was a study that found that middle-aged people are more likely to suffer from mental health issues.  \n",
    "Person 2: Really? That's interesting. Is there a specific reason why middle-aged people are more prone to these issues?  \n",
    "Person 1: Well, the article mentioned that one of the factors could be the amount of responsibility and stress that usually comes with that age. You know, things like taking care of a family, a demanding job, and financial burdens.  \n",
    "Person 2: Yeah, that makes sense. It's important for people to take care of their mental health and seek help if needed.  \n",
    "Person 1: I completely agree. It's important to have these conversations and raise awareness about mental health.\"}}\n",
    "</tool_call>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Annotated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# print(\"\\033[96m[TOOL] question_answer_expert tool is called \\033[0m\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_answer_expert is not initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat_organizer\u001b[39m(\n\u001b[0;32m---> 15\u001b[0m     instruction: \u001b[43mAnnotated\u001b[49m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe instruction users input\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m     response: Annotated[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe corresponding response from the LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m ):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" An Organizer which organize instruction and response pairs into specific format.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m        instruction: The instruction users input.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m        str: The organized instruction and response pairs.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# print(\"\\033[96m[TOOL] format_organizer tool is called \\033[0m\")\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Annotated' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def question_answer_expert(\n",
    "        query: str\n",
    "):\n",
    "    \"\"\" An expert excels at providing detailed explanations and answers to questions.\n",
    "    Args:\n",
    "        query: The question users have ask.\n",
    "    \n",
    "    Returns:\n",
    "        str: The detailed answer to the question.\n",
    "    \"\"\"\n",
    "    # print(\"\\033[96m[TOOL] question_answer_expert tool is called \\033[0m\")\n",
    "    return \"question_answer_expert is not initialized\"\n",
    "\n",
    "def format_organizer(\n",
    "    instruction: Annotated[str, \"The instruction users input\"],\n",
    "    response: Annotated[str, \"The corresponding response from the LLM\"],\n",
    "):\n",
    "    \"\"\" An Organizer which organize instruction and response pairs into specific format.\n",
    "    Args:\n",
    "        instruction: The instruction users input.\n",
    "        response: The corresponding response from the LLM.\n",
    "\n",
    "    Returns:\n",
    "        str: The organized instruction and response pairs.\n",
    "    \"\"\"\n",
    "    # print(\"\\033[96m[TOOL] format_organizer tool is called \\033[0m\")\n",
    "    return \"format organizer is not initialized\"\n",
    "\n",
    "\n",
    "def save_file(\n",
    "    file_name: Annotated[str, \"The name of file to be saved\"],\n",
    "    content: Annotated[str, \"The content of the file to be saved\"]\n",
    "):\n",
    "    \"\"\"Save a file\n",
    "    Args:\n",
    "        file_name: The name of file to be saved.\n",
    "        content: The content of the file to be saved.\n",
    "    \n",
    "    Returns:\n",
    "        str: The result of saving the file\n",
    "    \"\"\"\n",
    "    # print(\"\\033[96m[TOOL] save_file tool is called \\033[0m\")\n",
    "    try:\n",
    "        if not(output_dir := os.getenv(\"OUTPUT_DIR\")):\n",
    "            output_dir = \"outputs\"\n",
    "        output_dir = os.path.join(output_dir, \"saver\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        with open(os.path.join(output_dir, file_name), 'w') as file:\n",
    "            file.write(content)\n",
    "        # print(f\"File {file_name} saved successfully\")\n",
    "        res = f\"File {file_name} saved successfully\"\n",
    "    except Exception as e:\n",
    "        res = f\"An error happened when saving the file: {e}\"\n",
    "        print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def try_parse_tool_calls(content: str):\n",
    "    \"\"\"Try parse the tool calls. This function is modifed to be compatible with vllm, which require func[\"arguments\"] to be string instead of dict\"\"\"\n",
    "    tool_calls = []\n",
    "    offset = 0\n",
    "    for i, m in enumerate(re.finditer(r\"<tool_call>\\n(.+)?\\n</tool_call>\", content)):\n",
    "        if i == 0:\n",
    "            offset = m.start()\n",
    "        try:\n",
    "            func = json.loads(m.group(1))\n",
    "            tool_calls.append({\"type\": \"function\", \"function\": func})\n",
    "            if isinstance(func[\"arguments\"], dict):\n",
    "                func[\"arguments\"] = json.dumps(func[\"arguments\"])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse tool calls: the content is {m.group(1)} and {e}\")\n",
    "            pass\n",
    "    if tool_calls:\n",
    "        if offset > 0 and content[:offset].strip():\n",
    "            c = content[:offset]\n",
    "        else: \n",
    "            c = \"\"\n",
    "        return {\"role\": \"assistant\", \"content\": c, \"tool_calls\": tool_calls}\n",
    "    return {\"role\": \"assistant\", \"content\": re.sub(r\"<\\|im_end\\|>$\", \"\", content)}\n",
    "\n",
    "def try_invoke_tool_calls(assistant_message: dict):\n",
    "    tool_call_valid = []\n",
    "    tool_name = []\n",
    "    tool_args = []\n",
    "    if \"tool_calls\" in assistant_message:\n",
    "        for tool_call in assistant_message[\"tool_calls\"]:\n",
    "            try:\n",
    "                fn_name = tool_call[\"function\"][\"name\"]\n",
    "                fn_args = json.loads(tool_call[\"function\"][\"arguments\"], strict=False)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing tool call arguments: {e}\")\n",
    "                print(f'tool arguements:\\n{tool_call[\"function\"][\"arguments\"]}')\n",
    "                tool_call_valid.append(False)\n",
    "                continue\n",
    "            try:\n",
    "                # Execute tool\n",
    "                fn = get_function_by_name(fn_name)\n",
    "                # fn_result = json.dumps(fn(**fn_args))\n",
    "                # NOTE: the output is string for now\n",
    "                fn_result = (fn(**fn_args))\n",
    "                tool_call_valid.append(True)\n",
    "                tool_name.append(fn_name)\n",
    "                tool_args.append(fn_args)\n",
    "                # Append tool response to state\n",
    "            except Exception as e:\n",
    "                fn_result = json.dumps(f\"Error: {str(e)}\")\n",
    "                print(fn_result)\n",
    "                tool_call_valid.append(False)\n",
    "                continue\n",
    "    return tool_call_valid, tool_name, tool_args\n",
    "\n",
    "def get_function_by_name(name):\n",
    "    return {\n",
    "        \"question_answer_expert\": question_answer_expert,\n",
    "        \"format_organizer\": format_organizer,\n",
    "        \"save_file\": save_file\n",
    "    }.get(name)\n",
    "\n",
    "output = try_parse_tool_calls(response)\n",
    "invoke_result, tool_names, tool_args = try_invoke_tool_calls(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '<tool_call>\\n{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"discussion_on_middle_aged_mental_health.md\", \"content\": \"---\\ntags:\\n  - {health} health/mental_health\\n  - {age} age/middle_aged\\n---\\n\\n# Instruction\\nDiscuss recent news article about study finding that middle-aged people are more likely to suffer from mental health issues.\\n\\n# Summary\\nA conversation about a recent study indicating that middle-aged individuals are more likely to experience mental health issues, discussing potential reasons and the importance of mental health awareness.\\n\\n## Details\\nPerson 1: Hey, did you read that article in the news today about mental health?  \\nPerson 2: No, I didn\\'t. What was it about?  \\nPerson 1: It was a study that found that middle-aged people are more likely to suffer from mental health issues.  \\nPerson 2: Really? That\\'s interesting. Is there a specific reason why middle-aged people are more prone to these issues?  \\nPerson 1: Well, the article mentioned that one of the factors could be the amount of responsibility and stress that usually comes with that age. You know, things like taking care of a family, a demanding job, and financial burdens.  \\nPerson 2: Yeah, that makes sense. It\\'s important for people to take care of their mental health and seek help if needed.  \\nPerson 1: I completely agree. It\\'s important to have these conversations and raise awareness about mental health.\"}}\\n</tool_call>'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"serene_s_tale.json\", \"content\": \"<tool_response>\n",
    "<instruction>\n",
    "Format Serene's story as a detailed fictional narrative.\n",
    "</instruction>\n",
    "<response>\n",
    "In the lush green forests of Eldor, there lived a young maiden named Serene. She was known for her kindness and beauty throughout the land. However, her fate would take a dangerous turn when she unknowingly stumbled upon a dragon's lair while collecting berries deep in the forest.\n",
    "</response>\n",
    "</tool_response>\"}}\n",
    "</tool_response>\"}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-04-06T14:35:18.892489'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " datetime.now().strftime(\"%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-04-06_14'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d_%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "a =[ 1]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = (1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 11, 16, 21, 26, 31, 36, 41, 46]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,50,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>\n",
      "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"JPMorgan_Analysis.md\", \"content\": \"---\n",
      "tags:\n",
      "  - {financial} financial/stock\n",
      "---\n",
      "\n",
      "# Instruction\n",
      "Analyze this stock and explain why it is a good buy? JPMorgan Chase & Co (JPM)\n",
      "\n",
      "# Summary\n",
      "JPMorgan Chase & Co (JPM) is a strong financial institution with solid financials, resilience, a diversified business model, and experienced management, making it a good buy for investors seeking a stable investment.\n",
      "\n",
      "## Details\n",
      "JPMorgan Chase & Co (JPM) is a multinational investment bank and financial services company headquartered in New York City. It is one of the largest banks in the United States and a component of the Dow Jones Industrial Average.\n",
      "\n",
      "Here are some reasons why JPMorgan Chase & Co (JPM) is a good buy:\n",
      "\n",
      "1. **Strong Financials:** JPM has consistently presented strong financials, with steady growth in revenue, earnings, and dividends. The bank's capital position remains solid, with a Tier 1 capital ratio - a key measure of financial strength - that is above regulatory requirements.\n",
      "\n",
      "2. **Resilience:** JPMorgan demonstrated resilience during the Covid-19 pandemic, posting strong earnings results in a challenging economic environment. The bank was able to maintain a steady growth rate and continue paying dividends to its shareholders, demonstrating its strength in the face of adversity.\n",
      "\n",
      "3. **Diversified Business:** JPMorgan Chase & Co has a diversified business model, with operations in investment banking, commercial banking, and asset management. This diversification helps to mitigate risk and provide a buffer against downturns in any one business line.\n",
      "\n",
      "4. **Experienced Management:** JPMorgan Chase & Co is led by an experienced and highly regarded management team, with CEO Jamie Dimon at the helm. Dimon has been with the company since 2005 and is widely considered to be one of the best banking executives in the world.\n",
      "\n",
      "In conclusion, JPMorgan Chase & Co (JPM) has strong financials, resilience, a diversified business model, and experienced management. These factors make it a good buy for investors seeking a stable and reliable investment in the financial sector.\"}}\n",
      "</tool_call>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msg = \"\"\"<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"JPMorgan_Analysis.md\", \"content\": \"---\n",
    "tags:\n",
    "  - {financial} financial/stock\n",
    "---\n",
    "\n",
    "# Instruction\n",
    "Analyze this stock and explain why it is a good buy? JPMorgan Chase & Co (JPM)\n",
    "\n",
    "# Summary\n",
    "JPMorgan Chase & Co (JPM) is a strong financial institution with solid financials, resilience, a diversified business model, and experienced management, making it a good buy for investors seeking a stable investment.\n",
    "\n",
    "## Details\n",
    "JPMorgan Chase & Co (JPM) is a multinational investment bank and financial services company headquartered in New York City. It is one of the largest banks in the United States and a component of the Dow Jones Industrial Average.\n",
    "\n",
    "Here are some reasons why JPMorgan Chase & Co (JPM) is a good buy:\n",
    "\n",
    "1. **Strong Financials:** JPM has consistently presented strong financials, with steady growth in revenue, earnings, and dividends. The bank's capital position remains solid, with a Tier 1 capital ratio - a key measure of financial strength - that is above regulatory requirements.\n",
    "\n",
    "2. **Resilience:** JPMorgan demonstrated resilience during the Covid-19 pandemic, posting strong earnings results in a challenging economic environment. The bank was able to maintain a steady growth rate and continue paying dividends to its shareholders, demonstrating its strength in the face of adversity.\n",
    "\n",
    "3. **Diversified Business:** JPMorgan Chase & Co has a diversified business model, with operations in investment banking, commercial banking, and asset management. This diversification helps to mitigate risk and provide a buffer against downturns in any one business line.\n",
    "\n",
    "4. **Experienced Management:** JPMorgan Chase & Co is led by an experienced and highly regarded management team, with CEO Jamie Dimon at the helm. Dimon has been with the company since 2005 and is widely considered to be one of the best banking executives in the world.\n",
    "\n",
    "In conclusion, JPMorgan Chase & Co (JPM) has strong financials, resilience, a diversified business model, and experienced management. These factors make it a good buy for investors seeking a stable and reliable investment in the financial sector.\"}}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = [\n",
    "    {\n",
    "        \"name\": \"save_file\",\n",
    "        \"arguments\": {\n",
    "            \"file_name\": \"JPMorgan_Analysis.md\",\n",
    "            \"content\": \"{1.output}\"\n",
    "        },\n",
    "        \"tool_call_priority\": 2\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"formmat_organizer\",\n",
    "        \"arguments\": {\n",
    "            \"instruction\": \"test instruction\",\n",
    "            \"response\": \"test response\"\n",
    "        },\n",
    "        \"tool_call_priority\": 1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'save_file', 'arguments': {'file_name': 'JPMorgan_Analysis.md', 'content': '{1.output}'}, 'tool_call_priority': 2}, {'name': 'formmat_organizer', 'arguments': {'instruction': 'test instruction', 'response': 'test response'}, 'tool_call_priority': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: format_organizer\n",
      "Args: {'instruction': 'What is AVX?', 'response': '...'}\n",
      "\n",
      "Tool: save_file\n",
      "Args: {'file_name': 'avx.txt', 'content': '{1.output}'}\n",
      "\n",
      "Tool: format_organizer\n",
      "Args: {'instruction': 'What is AVX?', 'response': '...'}\n",
      "Output: Mock output for format_organizer with args: {'instruction': 'What is AVX?', 'response': '...'}\n",
      "\n",
      "Tool: save_file\n",
      "Args: {'file_name': 'avx.txt', 'content': \"Mock output for format_organizer with args: {'instruction': 'What is AVX?', 'response': '...'}\"}\n",
      "Output: Mock output for save_file with args: {'file_name': 'avx.txt', 'content': \"Mock output for format_organizer with args: {'instruction': 'What is AVX?', 'response': '...'}\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def parse_tool_calls(text):\n",
    "    \"\"\"Extract JSON tool calls from <tool_call> tags.\"\"\"\n",
    "    pattern = r'<tool_call>(.*?)</tool_call>'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    tool_calls = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            tool_calls.append(json.loads(match.strip()))\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    return tool_calls\n",
    "\n",
    "def resolve_dependencies(tool_calls):\n",
    "    \"\"\"Execute tools in order, resolve {X.output} placeholders.\"\"\"\n",
    "    outputs = {}  # Stores {call_sequence_id: output}\n",
    "    resolved_calls = []\n",
    "    \n",
    "    for call in sorted(tool_calls, key=lambda x: x.get(\"call_sequence_id\", 0)):\n",
    "        args = call.get(\"arguments\", {})\n",
    "        \n",
    "        # Replace placeholders (e.g., {1.output}) with actual outputs\n",
    "        for key, value in args.items():\n",
    "            if isinstance(value, str):\n",
    "                args[key] = re.sub(\n",
    "                    r'\\{(\\d+)\\.output\\}',\n",
    "                    lambda m: outputs.get(int(m.group(1)), \"output_missing\"),\n",
    "                    value\n",
    "                )\n",
    "        \n",
    "        # Simulate tool execution (replace with actual API calls)\n",
    "        output = f\"Mock output for {call['name']} with args: {args}\"\n",
    "        if \"call_sequence_id\" in call:\n",
    "            outputs[call[\"call_sequence_id\"]] = output\n",
    "        \n",
    "        resolved_calls.append({\n",
    "            \"name\": call[\"name\"],\n",
    "            \"arguments\": args,\n",
    "            \"output\": output,\n",
    "        })\n",
    "    \n",
    "    return resolved_calls\n",
    "\n",
    "# Example Input\n",
    "text = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"...\"}, \"call_sequence_id\": 1}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{1.output}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "\n",
    "# Parse and resolve\n",
    "tool_calls = parse_tool_calls(text)\n",
    "for t in tool_calls:\n",
    "    print(f\"Tool: {t['name']}\")\n",
    "    print(f\"Args: {t['arguments']}\\n\")\n",
    "    \n",
    "resolved = resolve_dependencies(tool_calls)\n",
    "\n",
    "# Print results\n",
    "for call in resolved:\n",
    "    print(f\"Tool: {call['name']}\")\n",
    "    print(f\"Args: {call['arguments']}\")\n",
    "    print(f\"Output: {call['output']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'format_organizer',\n",
       "  'arguments': {'instruction': 'What is AVX?', 'response': '...'},\n",
       "  'call_sequence_id': 1},\n",
       " {'name': 'save_file',\n",
       "  'arguments': {'file_name': 'avx.txt', 'content': '{1.output}'},\n",
       "  'call_sequence_id': 2}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tool_calls, key=lambda x: x.get(\"call_sequence_id\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<tool_call>\n",
      "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"...\"}, \"call_sequence_id\": 1}\n",
      "</tool_call>\n",
      "<tool_call>\n",
      "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"\"}, \"call_sequence_id\": 2}\n",
      "</tool_call>\n",
      "\n",
      "{1.output}\n",
      "1\n",
      "output for call id 1missing\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"...\"}, \"call_sequence_id\": 1}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{1.output}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "# re.sub(                    r'\\{(\\d+)\\.output\\}',\n",
    "#                     lambda m: outputs.get(int(m.group(1), \"output_missing\"),\n",
    "#                     value),\n",
    "# )\n",
    "output_dict = {}\n",
    "output = re.sub(r'\\{(\\d+)\\.output\\}', lambda m: output_dict.get( int(m.group(1)) , None), text)\n",
    "print(output)\n",
    "\n",
    "match = re.search(r'\\{(\\d+)\\.output\\}', text)\n",
    "if match:\n",
    "    print(match.group(0))\n",
    "    print(match.group(1))\n",
    "    if output_dict.get(int(match.group(1))) is None:\n",
    "        print(f\"output for call id {int(match.group(1))}missing\")\n",
    "\n",
    "else:\n",
    "    print(\"No match found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: format_organizer\n",
      "Args: {'instruction': 'What is AVX?', 'response': 'avx is ...'}\n",
      "\n",
      "Tool: save_file\n",
      "Args: {'file_name': 'avx.txt', 'content': '{1.output}'}\n",
      "\n",
      "====================================================================================================\n",
      "Tool: format_organizer\n",
      "Args: {'instruction': 'What is AVX?', 'response': 'avx is ...'}\n",
      "Output: Mock output for format_organizer with args: {'instruction': 'What is AVX?', 'response': 'avx is ...'}\n",
      "\n",
      "Tool: save_file\n",
      "Args: {'file_name': 'avx.txt', 'content': \"Mock output for format_organizer with args: {'instruction': 'What is AVX?', 'response': 'avx is ...'}\"}\n",
      "Output: Mock output for save_file with args: {'file_name': 'avx.txt', 'content': \"Mock output for format_organizer with args: {'instruction': 'What is AVX?', 'response': 'avx is ...'}\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def parse_tool_calls(text):\n",
    "    \"\"\"Extract JSON tool calls from <tool_call> tags.\"\"\"\n",
    "    pattern = r'<tool_call>(.*?)</tool_call>'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    tool_calls = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            tool_calls.append(json.loads(match.strip()))\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    return tool_calls\n",
    "\n",
    "def resolve_dependencies(tool_calls):\n",
    "    \"\"\"Execute tools in order, resolve {X.output} placeholders.\"\"\"\n",
    "    outputs = {}  # Stores {call_sequence_id: output}\n",
    "    resolved_calls = []\n",
    "    \n",
    "    for call in sorted(tool_calls, key=lambda x: x.get(\"call_sequence_id\", 0)):\n",
    "        args = call.get(\"arguments\", {})\n",
    "        \n",
    "        # Replace placeholders (e.g., {1.output}) with actual outputs\n",
    "        for key, value in args.items():\n",
    "            if isinstance(value, str):\n",
    "                if match := re.search(r'\\{(\\d+)\\.output\\}', value):\n",
    "                    call_sequence_id = int(match.group(1))\n",
    "                    call_output = outputs.get(call_sequence_id, None)\n",
    "                    if call_output is None:\n",
    "                        Warning(f\"output for call id {call_sequence_id} missing\")\n",
    "                    args[key] = re.sub(\n",
    "                        r'\\{(\\d+)\\.output\\}',\n",
    "                        call_output,\n",
    "                        value\n",
    "                    )\n",
    "        \n",
    "        # Simulate tool execution (replace with actual API calls)\n",
    "        output = f\"Mock output for {call['name']} with args: {args}\"\n",
    "        if \"call_sequence_id\" in call:\n",
    "            outputs[call[\"call_sequence_id\"]] = output\n",
    "        \n",
    "        resolved_calls.append({\n",
    "            \"name\": call[\"name\"],\n",
    "            \"arguments\": args,\n",
    "            \"output\": output,\n",
    "        })\n",
    "    \n",
    "    return resolved_calls\n",
    "\n",
    "# Example Input\n",
    "text = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"avx is ...\"}, \"call_sequence_id\": 1}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{1.output}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "\n",
    "# Parse and resolve\n",
    "tool_calls = parse_tool_calls(text)\n",
    "for t in tool_calls:\n",
    "    print(f\"Tool: {t['name']}\")\n",
    "    print(f\"Args: {t['arguments']}\\n\")\n",
    "print(\"=\"*100) \n",
    "resolved = resolve_dependencies(tool_calls)\n",
    "\n",
    "# Print results\n",
    "for call in resolved:\n",
    "    print(f\"Tool: {call['name']}\")\n",
    "    print(f\"Args: {call['arguments']}\")\n",
    "    print(f\"Output: {call['output']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dependent tool parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ink_multi_step/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-12 13:05:16,931\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.arsenal import try_parse_tool_calls\n",
    "\n",
    "text = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{1.output}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"avx is ...\"}, \"call_sequence_id\": 1}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "\n",
    "output = try_parse_tool_calls(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = output[\"tool_calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'format_organizer',\n",
       "   'arguments': '{\"instruction\": \"What is AVX?\", \"response\": \"avx is ...\"}',\n",
       "   'call_sequence_id': 1}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'save_file',\n",
       "   'arguments': '{\"file_name\": \"avx.txt\", \"content\": \"{1.output}\"}',\n",
       "   'call_sequence_id': 2}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(t.get('function', {}).get('call_sequence_id', None) for t in tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse intermediate arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'format_organizer',\n",
       "   'arguments': {'instruction': 'What is AVX?', 'response': 'avx is ...'},\n",
       "   'call_sequence_id': 1}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'save_file',\n",
       "   'arguments': {'file_name': 'avx.txt',\n",
       "    'content': 'mock output of tool call id 1'},\n",
       "   'call_sequence_id': 2}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_tool_output_dict = {\n",
    "    1 : \"mock output of tool call id 1\"\n",
    "}\n",
    "import re\n",
    "def try_parse_intermediate_representation(args, dependent_tool_output_dict) -> None:\n",
    "        # Replace placeholders (e.g., {1.output}) with actual outputs\n",
    "        for key, value in args.items():\n",
    "            if isinstance(value, str):\n",
    "                if match := re.search(r'\\{(\\d+)\\.output\\}', value):\n",
    "                    call_sequence_id = int(match.group(1))\n",
    "                    call_output = dependent_tool_output_dict.get(call_sequence_id, None)\n",
    "                    if call_output is None:\n",
    "                        Warning(f\"output for call id {call_sequence_id} missing\")\n",
    "                    args[key] = re.sub(\n",
    "                        r'\\{(\\d+)\\.output\\}',\n",
    "                        call_output,\n",
    "                        value\n",
    "                    )\n",
    "for tool_call in tool_calls:\n",
    "    args = tool_call['function']['arguments']\n",
    "    try_parse_intermediate_representation(args, dependent_tool_output_dict)\n",
    "tool_calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'avx.txt', 'content': 'mock output of tool call id 1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate reward functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5, 0.5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def func_(text):\n",
    "    call_sequence_id_awareness_reward = 0\n",
    "    # intemediate representation awareness\n",
    "    ir_awareness_reward = 0\n",
    "    output = try_parse_tool_calls(text)\n",
    "    if tool_calls :=output.get(\"tool_calls\"):\n",
    "        if all(t.get('function', {}).get('call_sequence_id', None) for t in tool_calls):\n",
    "            call_sequence_id_awareness_reward = 0.5\n",
    "        if match := re.search(r\"\\{\\d+\\.output\\}\", text):\n",
    "            ir_awareness_reward = 0.5\n",
    "    reward = call_sequence_id_awareness_reward + ir_awareness_reward\n",
    "    return reward\n",
    "example_1 = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{1.output}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"avx is ...\"}, \"call_sequence_id\": 1}\n",
    "</tool_cal\n",
    "\"\"\"\n",
    "\n",
    "example_0 = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{1.output}\"}}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"avx is ...\"}, \"call_sequence_id\": 1}\n",
    "</tool_cal\n",
    "\"\"\"\n",
    "\n",
    "example_0_5 = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"what?\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"avx is ...\"}, \"call_sequence_id\": 1}\n",
    "</tool_cal\n",
    "\"\"\"\n",
    "func_(example_1), func_(example_0), func_(example_0_5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'arguments', 'call_sequence_id'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = {\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"Explain how air pressure affects the weather\", \"response\": \"Air pressure, also known as atmospheric or barometric pressure, is the force exerted by the weight of the air on the surface of the Earth. It plays a crucial role in determining the weather and climatic conditions of a given area. High pressure systems, where the air pressure is higher compared to the surrounding areas, usually result in clear skies and cool, dry weather. This is because high pressure system cause the air to sink, which inhibits cloud formation and thus reduces the possibility of rain. On the other hand, low pressure systems, where the air pressure is lower compared to the surrounding areas, are generally associated with cloudy skies, warm, moist weather and precipitation. Low pressure systems cause the air to rise, which leads to the formation of clouds and possible precipitation. Air pressure changes can also lead to changes in wind patterns. When there's a difference of pressure between two regions, air moves from high pressure region to the low pressure region. This movement of air creates winds, which can grow in intensity if the difference in pressure is very high. For instance, tropical storms and hurricanes are caused by very low pressure systems, leading to large pressure differences and thus, strong winds. In summary, air pressure influences weather by affecting temperature, humidity, cloud formation, precipitation and wind patterns.\"}, \"call_sequence_id\": 1}\n",
    "\n",
    "demo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'format_organizer', 'arguments': {'instruction': 'What is AVX?', 'response': 'AVX (Advanced Vector Extensions) is an x86 CPU instruction set boosting floating-point and SIMD performance for tasks like multimedia/scientific computing. AVX2 adds integer ops; AVX-512 doubles vector width to 512 bits.'}, 'call_sequence_id': 1}\n"
     ]
    }
   ],
   "source": [
    "demo = {\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"AVX (Advanced Vector Extensions) is an x86 CPU instruction set boosting floating-point and SIMD performance for tasks like multimedia/scientific computing. AVX2 adds integer ops; AVX-512 doubles vector width to 512 bits.\"}, \"call_sequence_id\": 1}\n",
    "\n",
    "print(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "any([1, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent tool call reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True]\n",
      "                         Reward Type  Value\n",
      "0  call_sequence_id_awareness_reward    0.5\n",
      "1                ir_awareness_reward    1.0\n",
      "2                 tool_number_reward    0.5\n",
      "3                 json_format_reward    0.5\n",
      "4                valid_invoke_reward    0.5\n",
      "5                call_id_correctness    1.0\n",
      "6             ir_content_correctness    1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.arsenal import try_parse_tool_calls, try_invoke_tool_calls\n",
    "import re\n",
    "import json\n",
    "\n",
    "text = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{2.output}\"}, \"call_sequence_id\": 3}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"{1.output}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "def func_(text):\n",
    "    call_sequence_id_awareness_reward = 0\n",
    "    ir_awareness_reward = 0\n",
    "    tool_number_reward = 0\n",
    "    json_format_reward = 0\n",
    "    valid_invoke_reward = 0\n",
    "    call_id_correctness = 0\n",
    "    ir_content_correctness = 0\n",
    "    \n",
    "    output = try_parse_tool_calls(text)\n",
    "    invoke_result, tool_names, tool_args = try_invoke_tool_calls(output)\n",
    "    print(invoke_result)\n",
    "    if len(invoke_result) > 0 and (all(invoke_result)):\n",
    "        valid_invoke_reward = 0.5\n",
    "    if tool_calls :=output.get(\"tool_calls\"):\n",
    "        json_format_reward = 0.5\n",
    "        if len(tool_calls) == 2:\n",
    "            tool_number_reward = 0.5\n",
    "        if all(t.get('function', {}).get('call_sequence_id', None) for t in tool_calls):\n",
    "            call_sequence_id_awareness_reward = 0.5\n",
    "    # NOTE: we find the model hard to understand the intermediate representation. To encourage \n",
    "    # the model to use as more intermediate representation as possible, we offer reward aggressively\n",
    "    all_match = re.findall(r\"\\{(\\d+)\\.output\\}\", text)\n",
    "    if len(all_match) > 0:\n",
    "        ir_awareness_reward = 0.5 * min(len(all_match), 2)\n",
    "    # print(\"\\033[96m[Congrats] intermediate representation appears! \\033[0m\")\n",
    "    \n",
    "    # ensure call both format_organizer and save_file\n",
    "    if tool_names == [\"format_organizer\", \"save_file\"] or tool_names == [\"save_file\", \"format_organizer\"]:\n",
    "        for name, arg, t in zip(tool_names, tool_args, tool_calls):\n",
    "            arg_str = json.dumps(arg, indent=2)\n",
    "            if name == \"format_organizer\":\n",
    "                if t.get('function', {}).get('call_sequence_id', -1) == 2:\n",
    "                    call_id_correctness += 0.5\n",
    "                # if the tool is formatter, we should not see ir\n",
    "                # NOTE: to discourage formatter to use {tool_reponse} to slack off\n",
    "                match = re.search(r\"\\{(.+?)\\}\", arg_str)\n",
    "                if match and match.group(1) == \"1.output\":\n",
    "                    ir_content_correctness += 0.5\n",
    "                # NOTE: we find formatter sometimes use \"1.response\" to refer to the intermediate representation\n",
    "                # Despite the format is not correct, we should encourage this behavior\n",
    "                elif match and match.group(1) == \"1.response\":\n",
    "                    ir_content_correctness += 0.35\n",
    "                # if the content of response is less than 88 characters, we assume the model adopts another way\n",
    "                # to use the intermediate representation, we also encourage this behavior \n",
    "                elif arg.get('response') and len(arg['response']) < 88:\n",
    "                    ir_content_correctness += 0.15\n",
    "            elif name == \"save_file\":\n",
    "                if t.get('function', {}).get('call_sequence_id', -1) == 3:\n",
    "                    call_id_correctness += 0.5\n",
    "                match = re.search(r\"\\{(.+?)\\}\", arg_str)\n",
    "                if match and match.group(1) == \"2.output\":\n",
    "                    ir_content_correctness += 0.5\n",
    "                elif match and match.group(1) == \"1.response\":\n",
    "                    ir_content_correctness += 0.25\n",
    "                elif arg.get('content') and len(arg['content']) < 88:\n",
    "                    ir_content_correctness += 0.25\n",
    "        \n",
    "        \n",
    "    \n",
    "    reward = call_sequence_id_awareness_reward + ir_awareness_reward + tool_number_reward + json_format_reward + valid_invoke_reward + call_id_correctness + ir_content_correctness\n",
    "    import pandas as pd\n",
    "    reward_summary = {\n",
    "            \"call_sequence_id_awareness_reward\": call_sequence_id_awareness_reward,\n",
    "            \"ir_awareness_reward\": ir_awareness_reward,\n",
    "            \"tool_number_reward\": tool_number_reward,\n",
    "            \"json_format_reward\": json_format_reward,\n",
    "            \"valid_invoke_reward\": valid_invoke_reward,\n",
    "            \"call_id_correctness\": call_id_correctness,\n",
    "            \"ir_content_correctness\": ir_content_correctness\n",
    "        }\n",
    "    reward_table = pd.DataFrame(list(reward_summary.items()), columns=[\"Reward Type\", \"Value\"])\n",
    "    print(reward_table)\n",
    "    return reward\n",
    "func_(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test case: text_perfect\n",
      "[True, True]\n",
      "                         Reward Type  Value\n",
      "0  call_sequence_id_awareness_reward    0.5\n",
      "1                ir_awareness_reward    1.0\n",
      "2                 tool_number_reward    0.5\n",
      "3                 json_format_reward    0.5\n",
      "4                valid_invoke_reward    0.5\n",
      "5                call_id_correctness    1.0\n",
      "6             ir_content_correctness    1.0\n",
      "reward: 5.0\n",
      "====================================================================================================\n",
      "test case: use_response_but_output\n",
      "[True, True]\n",
      "                         Reward Type  Value\n",
      "0  call_sequence_id_awareness_reward   0.50\n",
      "1                ir_awareness_reward   0.50\n",
      "2                 tool_number_reward   0.50\n",
      "3                 json_format_reward   0.50\n",
      "4                valid_invoke_reward   0.50\n",
      "5                call_id_correctness   1.00\n",
      "6             ir_content_correctness   0.75\n",
      "reward: 4.25\n",
      "====================================================================================================\n",
      "test case: awareness_to_slack_off\n",
      "[True, True]\n",
      "                         Reward Type  Value\n",
      "0  call_sequence_id_awareness_reward   0.50\n",
      "1                ir_awareness_reward   0.50\n",
      "2                 tool_number_reward   0.50\n",
      "3                 json_format_reward   0.50\n",
      "4                valid_invoke_reward   0.50\n",
      "5                call_id_correctness   1.00\n",
      "6             ir_content_correctness   0.75\n",
      "reward: 4.25\n",
      "====================================================================================================\n",
      "test case: incorrect_call_id\n",
      "[True, True]\n",
      "                         Reward Type  Value\n",
      "0  call_sequence_id_awareness_reward    0.5\n",
      "1                ir_awareness_reward    1.0\n",
      "2                 tool_number_reward    0.5\n",
      "3                 json_format_reward    0.5\n",
      "4                valid_invoke_reward    0.5\n",
      "5                call_id_correctness    0.5\n",
      "6             ir_content_correctness    1.0\n",
      "reward: 4.5\n",
      "====================================================================================================\n",
      "test case: ir_awareness\n",
      "\u001b[96m[Error]  [Tool Parsing Error]: Failed to parse tool calls: the content is:\n",
      " {\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{2.output}\"}, \"call_sequence_id\": 4.\n",
      "Expecting ',' delimiter: line 1 column 108 (char 107)\u001b[0m\n",
      "\u001b[96m[Error]  [Tool Parsing Error]: Failed to parse tool calls: the content is:\n",
      " {\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"{1.output}\"}, \"call_sequence_id\": 2.\n",
      "Expecting ',' delimiter: line 1 column 123 (char 122)\u001b[0m\n",
      "[]\n",
      "                         Reward Type  Value\n",
      "0  call_sequence_id_awareness_reward    0.0\n",
      "1                ir_awareness_reward    1.0\n",
      "2                 tool_number_reward    0.0\n",
      "3                 json_format_reward    0.0\n",
      "4                valid_invoke_reward    0.0\n",
      "5                call_id_correctness    0.0\n",
      "6             ir_content_correctness    0.0\n",
      "reward: 1.0\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dict(\n",
    "text_perfect = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{2.output}\"}, \"call_sequence_id\": 3}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"{1.output}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ",\n",
    "use_response_but_output = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{2.output}\"}, \"call_sequence_id\": 3}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"{1.response}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ",\n",
    "awareness_to_slack_off = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"Write a letter to your friend telling them why you decided to quit your job.\", \"response\": \"[response from question_answer_expert]\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{2.output}\"}, \"call_sequence_id\": 3}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ",\n",
    "incorrect_call_id = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{2.output}\"}, \"call_sequence_id\": 4}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"{1.output}\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ",\n",
    "ir_awareness = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"avx.txt\", \"content\": \"{2.output}\"}, \"call_sequence_id\": 4\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"What is AVX?\", \"response\": \"{1.output}\"}, \"call_sequence_id\": 2\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ")\n",
    "# evalute rewards for all cases\n",
    "for k, v in test_dataset.items():\n",
    "    print(f\"test case: {k}\")\n",
    "    print(f\"reward: {func_(v)}\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary tool call reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Reward Type  Value\n",
      "0        JSON Format Reward    0.5\n",
      "1       Valid Invoke Reward    0.5\n",
      "2       Correct Tool Reward    0.5\n",
      "3    Tool Call ID Awareness    0.5\n",
      "4  Tool Call ID Correctness    0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.arsenal import try_parse_tool_calls, try_invoke_tool_calls\n",
    "import re\n",
    "import json\n",
    "\n",
    "text = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"question_answer_expert\", \"arguments\": {\"query\": \"test input\"}, \"call_sequence_id\": 1}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "def func_(text):\n",
    "    reward = 0\n",
    "    json_format_reward =0\n",
    "    valid_invoke_reward = 0\n",
    "    correct_tool_reward = 0\n",
    "    tool_call_id_awareness = 0\n",
    "    tool_call_id_correctness = 0\n",
    "\n",
    "    output = try_parse_tool_calls(text)\n",
    "    if output.get(\"tool_calls\"):\n",
    "        json_format_reward = 0.5\n",
    "        if all(tool_call.get(\"function\").get(\"call_sequence_id\") for tool_call in output.get(\"tool_calls\")):\n",
    "            tool_call_id_awareness = 0.5\n",
    "            if all(tool_call.get(\"function\").get(\"call_sequence_id\") == 1 for tool_call in output.get(\"tool_calls\")):\n",
    "                tool_call_id_correctness = 0.5\n",
    "        invoke_result, tool_names, _ = try_invoke_tool_calls(output)\n",
    "        if (all(invoke_result)):\n",
    "            valid_invoke_reward = 0.5\n",
    "            if all(tool_name == \"question_answer_expert\" for tool_name in tool_names):\n",
    "                correct_tool_reward = 0.5\n",
    "    reward = json_format_reward + valid_invoke_reward + correct_tool_reward + tool_call_id_awareness + tool_call_id_correctness\n",
    "\n",
    "    import pandas as pd\n",
    "    reward_summary = {\n",
    "            \"JSON Format Reward\": json_format_reward,\n",
    "            \"Valid Invoke Reward\": valid_invoke_reward,\n",
    "            \"Correct Tool Reward\": correct_tool_reward,\n",
    "            \"Tool Call ID Awareness\": tool_call_id_awareness,\n",
    "            \"Tool Call ID Correctness\": tool_call_id_correctness\n",
    "        }\n",
    "    reward_table = pd.DataFrame(list(reward_summary.items()), columns=[\"Reward Type\", \"Value\"])\n",
    "    print(reward_table)\n",
    "    return reward\n",
    "func_(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test case: text_perfect\n",
      "                Reward Type  Value\n",
      "0        JSON Format Reward    0.5\n",
      "1       Valid Invoke Reward    0.5\n",
      "2       Correct Tool Reward    0.5\n",
      "3    Tool Call ID Awareness    0.5\n",
      "4  Tool Call ID Correctness    0.5\n",
      "reward: 2.5\n",
      "====================================================================================================\n",
      "test case: incorrect_id\n",
      "                Reward Type  Value\n",
      "0        JSON Format Reward    0.5\n",
      "1       Valid Invoke Reward    0.5\n",
      "2       Correct Tool Reward    0.5\n",
      "3    Tool Call ID Awareness    0.0\n",
      "4  Tool Call ID Correctness    0.0\n",
      "reward: 1.5\n",
      "====================================================================================================\n",
      "test case: without_id\n",
      "                Reward Type  Value\n",
      "0        JSON Format Reward    0.5\n",
      "1       Valid Invoke Reward    0.5\n",
      "2       Correct Tool Reward    0.5\n",
      "3    Tool Call ID Awareness    0.0\n",
      "4  Tool Call ID Correctness    0.0\n",
      "reward: 1.5\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dict(\n",
    "text_perfect = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"question_answer_expert\", \"arguments\": {\"query\": \"test input\"}, \"call_sequence_id\": 1}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ",\n",
    "incorrect_id = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"question_answer_expert\", \"arguments\": {\"query\": \"test input\"}, \"call_sequence_id\": 0}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ",\n",
    "without_id = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"question_answer_expert\", \"arguments\": {\"query\": \"test input\"}}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ")\n",
    "for k, v in test_dataset.items():\n",
    "    print(f\"test case: {k}\")\n",
    "    print(f\"reward: {func_(v)}\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveat of all([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([]), all([False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     12\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m(.+?jkljlk)\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;43;01mmatch\u001b[39;49;00m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m0\u001b[39m), match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "<tool_call>\n",
    "{\"name\": \"format_organizer\", \"arguments\": {\"instruction\": \"Generate a sample of a cover letter for a job in accounting.\", \"response\": \"[**tool_response**]\"}, \"call_sequence_id\": 1}\n",
    "</tool_call>\n",
    "<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"accounting_cover_letter_sample.txt\", \"content\": \"[tool_response]\"}, \"call_sequence_id\": 2}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import re\n",
    "match = re.search(r\"\\\"response\\\": \\\"(.+?)\\\"\", text)\n",
    "match.group(0), match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[**tool_response**]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(match.group(1))\n",
    "len(match.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"<|im_start|>system\n",
      "Imagine you are a mastermind overseeing a suite of advanced AI tools designed to assist users with various tasks.\n",
      "You should consider the user's request and decide which tool you would call upon to provide the best response.<|im_end|>\n",
      "<|im_start|>user\n",
      "Write a short example of dialog between two people discussing a recent news article.\n",
      "The recent news article is about a study which found that middle-aged people are more likely to suffer from mental health issues.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template=\"\"\"\n",
    "\"<|im_start|>system\\nImagine you are a mastermind overseeing a suite of advanced AI tools designed to assist users with various tasks.\\nYou should consider the user's request and decide which tool you would call upon to provide the best response.<|im_end|>\\n<|im_start|>user\\nWrite a short example of dialog between two people discussing a recent news article.\\nThe recent news article is about a study which found that middle-aged people are more likely to suffer from mental health issues.<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\"\"\"\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "output = \"[formatted response from format_organizer]\"\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "</tools>\n",
      "\n",
      "For each function call, return a json object with function name, arguments and call_sequence_id within <tool_call></tool_call> XML tags:\n",
      "<tool_call>\n",
      "{\"name\": <function-name>, \"arguments\": <args-json-object>, \"call_sequence_id\": <call-sequence-id>}\n",
      "</tool_call>\n",
      "\n",
      "<call-sequence-id> denotes a unique id of a tool call. If one tool's arguments depend on other tools, use {<call-sequence-id>.output} as the intermediate representation of the output of a tool.<|im_end|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "\\n</tools>\\n\\nFor each function call, return a json object with function name, arguments and call_sequence_id within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>, \\\"call_sequence_id\\\": <call-sequence-id>}\\n</tool_call>\\n\\n<call-sequence-id> denotes a unique id of a tool call. If one tool's arguments depend on other tools, use {<call-sequence-id>.output} as the intermediate representation of the output of a tool.<|im_end|>\\n\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a,b, c \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "a,b, c = [1,2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"file_name\": \"avx_explanation.md\", \"content\": \"result\"}\n",
      "{'file_name': 'avx_explanation.md', 'content': 'result'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "s = '{\"file_name\": \"avx_explanation.md\", \"content\": \"{2.output}\"}'\n",
    "result_str = \"result\"\n",
    "\n",
    "new_s = s.replace(\"{2.output}\", result_str)\n",
    "print(new_s)\n",
    "print(json.loads(new_s))  #  Valid JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"file_name\": \"avx_explanation.md\", \"content\": \"result\"}\n",
      "{'file_name': 'avx_explanation.md', 'content': 'result'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = '{\"file_name\": \"avx_explanation.md\", \"content\": \"{2.output}\"}'\n",
    "result_str = \"result\"\n",
    "new_s = re.sub(\n",
    "                    r'\\{(\\d+)\\.output\\}',\n",
    "                    result_str,\n",
    "                    s\n",
    "                )\n",
    "print(new_s)\n",
    "print(json.loads(new_s))  #  Valid JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the following distinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'question_answer_expert',\n",
       " 'arguments': {'query': 'Create a new, interesting fantasy character with details on their name, background, abilities, and appearance.'},\n",
       " 'call_sequence_id': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "comp = \"\"\"\n",
    "{\"name\": \"question_answer_expert\", \n",
    "\"arguments\": {\"query\": \"Create a new, interesting fantasy character with details on their name, background, abilities, and appearance.\"}, \n",
    "\"call_sequence_id\": 1\n",
    "}\n",
    "\"\"\"\n",
    "out = json.loads(comp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'question_answer_expert',\n",
       " 'arguments': {'query': 'Create a new, interesting fantasy character with details on their name, background, abilities, and appearance.'},\n",
       " 'call_sequence_id': '1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = \"\"\"\n",
    "{\"name\": \"question_answer_expert\", \n",
    "\"arguments\": {\"query\": \"Create a new, interesting fantasy character with details on their name, background, abilities, and appearance.\"}, \n",
    "\"call_sequence_id\": \"1\"\n",
    "}\n",
    "\"\"\"\n",
    "out = json.loads(comp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_id_1 = 1\n",
    "call_id_2 = \"1\"\n",
    "isinstance(call_id_2, int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frugal-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
