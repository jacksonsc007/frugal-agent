{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1]]\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    [0],\n",
    "    [1]\n",
    "]\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'foo'], [1, 'foo']]\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    [0],\n",
    "    [1]\n",
    "]\n",
    "print(prompt)\n",
    "def foo(prompt):\n",
    "    for p in prompt:\n",
    "        p. append(\"foo\")\n",
    "foo(prompt)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0], [1])\n",
      "([0, 'foo'], [1, 'foo'])\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    [0],\n",
    "    [1]\n",
    ")\n",
    "print(prompt)\n",
    "def foo(prompt):\n",
    "    for p in prompt:\n",
    "        p. append(\"foo\")\n",
    "foo(prompt)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1]]\n",
      "[[0, 'foo'], [1, 'foo']]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "prompt = [[0], [1]]\n",
    "new_prompt = copy.deepcopy(prompt)  # Creates a new independent copy\n",
    "\n",
    "foo(new_prompt)  # Modifies only 'new_prompt'\n",
    "print(prompt)  # Output: [[0], [1]]\n",
    "print(new_prompt)  # Output: [[0, \"foo\"], [1, \"foo\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call': 'true'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    \"tool_call\": \"true\"\n",
    "}\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'tool_call': 'true'}\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': '{\"a\": 1}'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    \"args\": '{\"a\": 1}'\n",
    "}\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': '{\"a\": 1}'}\n"
     ]
    }
   ],
   "source": [
    "def foo(d1):\n",
    "    print(d1)\n",
    "foo(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['name1', 'name2']\n",
    "b = ['name1', 'name2']\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.remove('name1')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name1', 'name2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [1, 1]\n",
    "c == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmean\u001b[49m([torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m2\u001b[39m)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "mean([torch.tensor(1), torch.tensor(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '':\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if 'a':\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0', '1', '0', '1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    '1' if i % 2 == 0 else '0' for i in range(5) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a =[1,2,3]\n",
    "a = torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.expand(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs/text.md'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "a = 'outputs'\n",
    "b = 'text.md'\n",
    "os.path.join(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"OUTPUT_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "pseudo_loss = torch.tensor(0.0, requires_grad=True)\n",
    "pseudo_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_loss.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you are a mastermind overseeing a suite of advanced AI tools designed to assist users with various tasks.\n",
      "You should consider the user's request and decide which tool you would call upon to provide the best response.\n",
      "If the user does not explicitly specify arguments of tools, you should deduce it from the context.\n",
      "For instance, the default file type for the tool 'save_file' is markdown. Besides, when you decides to call 'sav_file' tool to save the formatted content, you should pass the entire intact formatted content to it.\n"
     ]
    }
   ],
   "source": [
    "MASTERMIND_SYS_PROMPT_TOOL_SPECIFIC = \"\"\"\\\n",
    "Imagine you are a mastermind overseeing a suite of advanced AI tools designed to assist users with various tasks.\n",
    "You should consider the user's request and decide which tool you would call upon to provide the best response.\n",
    "If the user does not explicitly specify arguments of tools, you should deduce it from the context.\n",
    "For instance, the default file type for the tool 'save_file' is markdown. Besides, when you decides to call 'sav_file' tool to save the formatted content, you should pass the entire intact formatted content to it.\\\n",
    "\"\"\"\n",
    "print(MASTERMIND_SYS_PROMPT_TOOL_SPECIFIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response =\"\"\"<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"discussion_on_middle_aged_mental_health.md\", \"content\": \"---\n",
    "tags:\n",
    "  - {health} health/mental_health\n",
    "  - {age} age/middle_aged\n",
    "---\n",
    "\n",
    "# Instruction\n",
    "Discuss recent news article about study finding that middle-aged people are more likely to suffer from mental health issues.\n",
    "\n",
    "# Summary\n",
    "A conversation about a recent study indicating that middle-aged individuals are more likely to experience mental health issues, discussing potential reasons and the importance of mental health awareness.\n",
    "\n",
    "## Details\n",
    "Person 1: Hey, did you read that article in the news today about mental health?  \n",
    "Person 2: No, I didn't. What was it about?  \n",
    "Person 1: It was a study that found that middle-aged people are more likely to suffer from mental health issues.  \n",
    "Person 2: Really? That's interesting. Is there a specific reason why middle-aged people are more prone to these issues?  \n",
    "Person 1: Well, the article mentioned that one of the factors could be the amount of responsibility and stress that usually comes with that age. You know, things like taking care of a family, a demanding job, and financial burdens.  \n",
    "Person 2: Yeah, that makes sense. It's important for people to take care of their mental health and seek help if needed.  \n",
    "Person 1: I completely agree. It's important to have these conversations and raise awareness about mental health.\"}}\n",
    "</tool_call>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Annotated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# print(\"\\033[96m[TOOL] question_answer_expert tool is called \\033[0m\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_answer_expert is not initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat_organizer\u001b[39m(\n\u001b[0;32m---> 15\u001b[0m     instruction: \u001b[43mAnnotated\u001b[49m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe instruction users input\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m     response: Annotated[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe corresponding response from the LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m ):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" An Organizer which organize instruction and response pairs into specific format.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m        instruction: The instruction users input.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m        str: The organized instruction and response pairs.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# print(\"\\033[96m[TOOL] format_organizer tool is called \\033[0m\")\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Annotated' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def question_answer_expert(\n",
    "        query: str\n",
    "):\n",
    "    \"\"\" An expert excels at providing detailed explanations and answers to questions.\n",
    "    Args:\n",
    "        query: The question users have ask.\n",
    "    \n",
    "    Returns:\n",
    "        str: The detailed answer to the question.\n",
    "    \"\"\"\n",
    "    # print(\"\\033[96m[TOOL] question_answer_expert tool is called \\033[0m\")\n",
    "    return \"question_answer_expert is not initialized\"\n",
    "\n",
    "def format_organizer(\n",
    "    instruction: Annotated[str, \"The instruction users input\"],\n",
    "    response: Annotated[str, \"The corresponding response from the LLM\"],\n",
    "):\n",
    "    \"\"\" An Organizer which organize instruction and response pairs into specific format.\n",
    "    Args:\n",
    "        instruction: The instruction users input.\n",
    "        response: The corresponding response from the LLM.\n",
    "\n",
    "    Returns:\n",
    "        str: The organized instruction and response pairs.\n",
    "    \"\"\"\n",
    "    # print(\"\\033[96m[TOOL] format_organizer tool is called \\033[0m\")\n",
    "    return \"format organizer is not initialized\"\n",
    "\n",
    "\n",
    "def save_file(\n",
    "    file_name: Annotated[str, \"The name of file to be saved\"],\n",
    "    content: Annotated[str, \"The content of the file to be saved\"]\n",
    "):\n",
    "    \"\"\"Save a file\n",
    "    Args:\n",
    "        file_name: The name of file to be saved.\n",
    "        content: The content of the file to be saved.\n",
    "    \n",
    "    Returns:\n",
    "        str: The result of saving the file\n",
    "    \"\"\"\n",
    "    # print(\"\\033[96m[TOOL] save_file tool is called \\033[0m\")\n",
    "    try:\n",
    "        if not(output_dir := os.getenv(\"OUTPUT_DIR\")):\n",
    "            output_dir = \"outputs\"\n",
    "        output_dir = os.path.join(output_dir, \"saver\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        with open(os.path.join(output_dir, file_name), 'w') as file:\n",
    "            file.write(content)\n",
    "        # print(f\"File {file_name} saved successfully\")\n",
    "        res = f\"File {file_name} saved successfully\"\n",
    "    except Exception as e:\n",
    "        res = f\"An error happened when saving the file: {e}\"\n",
    "        print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def try_parse_tool_calls(content: str):\n",
    "    \"\"\"Try parse the tool calls. This function is modifed to be compatible with vllm, which require func[\"arguments\"] to be string instead of dict\"\"\"\n",
    "    tool_calls = []\n",
    "    offset = 0\n",
    "    for i, m in enumerate(re.finditer(r\"<tool_call>\\n(.+)?\\n</tool_call>\", content)):\n",
    "        if i == 0:\n",
    "            offset = m.start()\n",
    "        try:\n",
    "            func = json.loads(m.group(1))\n",
    "            tool_calls.append({\"type\": \"function\", \"function\": func})\n",
    "            if isinstance(func[\"arguments\"], dict):\n",
    "                func[\"arguments\"] = json.dumps(func[\"arguments\"])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse tool calls: the content is {m.group(1)} and {e}\")\n",
    "            pass\n",
    "    if tool_calls:\n",
    "        if offset > 0 and content[:offset].strip():\n",
    "            c = content[:offset]\n",
    "        else: \n",
    "            c = \"\"\n",
    "        return {\"role\": \"assistant\", \"content\": c, \"tool_calls\": tool_calls}\n",
    "    return {\"role\": \"assistant\", \"content\": re.sub(r\"<\\|im_end\\|>$\", \"\", content)}\n",
    "\n",
    "def try_invoke_tool_calls(assistant_message: dict):\n",
    "    tool_call_valid = []\n",
    "    tool_name = []\n",
    "    tool_args = []\n",
    "    if \"tool_calls\" in assistant_message:\n",
    "        for tool_call in assistant_message[\"tool_calls\"]:\n",
    "            try:\n",
    "                fn_name = tool_call[\"function\"][\"name\"]\n",
    "                fn_args = json.loads(tool_call[\"function\"][\"arguments\"], strict=False)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing tool call arguments: {e}\")\n",
    "                print(f'tool arguements:\\n{tool_call[\"function\"][\"arguments\"]}')\n",
    "                tool_call_valid.append(False)\n",
    "                continue\n",
    "            try:\n",
    "                # Execute tool\n",
    "                fn = get_function_by_name(fn_name)\n",
    "                # fn_result = json.dumps(fn(**fn_args))\n",
    "                # NOTE: the output is string for now\n",
    "                fn_result = (fn(**fn_args))\n",
    "                tool_call_valid.append(True)\n",
    "                tool_name.append(fn_name)\n",
    "                tool_args.append(fn_args)\n",
    "                # Append tool response to state\n",
    "            except Exception as e:\n",
    "                fn_result = json.dumps(f\"Error: {str(e)}\")\n",
    "                print(fn_result)\n",
    "                tool_call_valid.append(False)\n",
    "                continue\n",
    "    return tool_call_valid, tool_name, tool_args\n",
    "\n",
    "def get_function_by_name(name):\n",
    "    return {\n",
    "        \"question_answer_expert\": question_answer_expert,\n",
    "        \"format_organizer\": format_organizer,\n",
    "        \"save_file\": save_file\n",
    "    }.get(name)\n",
    "\n",
    "output = try_parse_tool_calls(response)\n",
    "invoke_result, tool_names, tool_args = try_invoke_tool_calls(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '<tool_call>\\n{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"discussion_on_middle_aged_mental_health.md\", \"content\": \"---\\ntags:\\n  - {health} health/mental_health\\n  - {age} age/middle_aged\\n---\\n\\n# Instruction\\nDiscuss recent news article about study finding that middle-aged people are more likely to suffer from mental health issues.\\n\\n# Summary\\nA conversation about a recent study indicating that middle-aged individuals are more likely to experience mental health issues, discussing potential reasons and the importance of mental health awareness.\\n\\n## Details\\nPerson 1: Hey, did you read that article in the news today about mental health?  \\nPerson 2: No, I didn\\'t. What was it about?  \\nPerson 1: It was a study that found that middle-aged people are more likely to suffer from mental health issues.  \\nPerson 2: Really? That\\'s interesting. Is there a specific reason why middle-aged people are more prone to these issues?  \\nPerson 1: Well, the article mentioned that one of the factors could be the amount of responsibility and stress that usually comes with that age. You know, things like taking care of a family, a demanding job, and financial burdens.  \\nPerson 2: Yeah, that makes sense. It\\'s important for people to take care of their mental health and seek help if needed.  \\nPerson 1: I completely agree. It\\'s important to have these conversations and raise awareness about mental health.\"}}\\n</tool_call>'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"<tool_call>\n",
    "{\"name\": \"save_file\", \"arguments\": {\"file_name\": \"serene_s_tale.json\", \"content\": \"<tool_response>\n",
    "<instruction>\n",
    "Format Serene's story as a detailed fictional narrative.\n",
    "</instruction>\n",
    "<response>\n",
    "In the lush green forests of Eldor, there lived a young maiden named Serene. She was known for her kindness and beauty throughout the land. However, her fate would take a dangerous turn when she unknowingly stumbled upon a dragon's lair while collecting berries deep in the forest.\n",
    "</response>\n",
    "</tool_response>\"}}\n",
    "</tool_response>\"}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-04-06T14:35:18.892489'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " datetime.now().strftime(\"%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-04-06_14'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d_%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "a =[ 1]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = (1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 11, 16, 21, 26, 31, 36, 41, 46]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,50,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl_tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
