{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optinal\n",
    "import os\n",
    "os.environ[\"https_proxy\"] = \"http://192.168.1.12:7891\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data with markdown heading struture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "# from utils.sys_prompts import IT_SYS_PROMPT as SYSTEM_PROMPT\n",
    "# from utils.sys_prompts import IT_SYS_PROMPT_deepseek_concise as SYSTEM_PROMPT\n",
    "from utils.sys_prompts import SYS_PROMPT_formatter_deepseek_concise_2 as SYSTEM_PROMPT\n",
    "import random\n",
    "\n",
    "INSTRUCTION_RESPONSE_FORMAT = \"\"\"\\\n",
    "<instruction>\n",
    "{instruction}\n",
    "</instruction>\n",
    "<response>\n",
    "{response}\n",
    "</response>\n",
    "\"\"\"\n",
    "\n",
    "def get_markdown_structure_data(url, split=\"train\", output_file=\"dataset.json\"):\n",
    "    dataset = load_dataset(url, split=split)\n",
    "    # since we want to emphasize the logical hierarchy\n",
    "    def check_structure_markdown(text):\n",
    "        structure_markdown_regrex = r\"^#{1,6} .*$\"\n",
    "        res = re.findall(structure_markdown_regrex, text[\"output\"], re.MULTILINE)\n",
    "        if len(res) > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def check_length(text):\n",
    "        length = len(text[\"output\"])\n",
    "        if  (length > 50) and (length < 2000):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    dataset = dataset.filter(\n",
    "        check_structure_markdown,\n",
    "    )\n",
    "    dataset = dataset.filter(\n",
    "        check_length,\n",
    "    )\n",
    "    print(\"\\033[92m Number of data after filtering: \\033[0m\", len(dataset))\n",
    "    \n",
    "    def formatting_prompts_func(examples):\n",
    "        instruction = examples[\"instruction\"]\n",
    "        input       = examples[\"input\"]\n",
    "        output      = examples[\"output\"]\n",
    "        return {\n",
    "            'prompt': [\n",
    "                {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "                # few-shot\n",
    "                # {'role': 'user', 'content': INSTRUCTION_RESPONSE_FORMAT.format(instruction=(fewshot_example[\"instruction\"]+fewshot_example[\"input\"]).strip(), response=fewshot_example['output'])},\n",
    "                # {'role': 'assistant', 'content': fewshot_response},\n",
    "                {'role': 'user', 'content': INSTRUCTION_RESPONSE_FORMAT.format(instruction=(instruction+input).strip(), response=output)}\n",
    "            ],\n",
    "            # 'answer': extract_hash_answer(output)\n",
    "        }\n",
    "    \n",
    "    dataset = dataset.map(formatting_prompts_func, batched=False)\n",
    "    dataset = dataset.remove_columns([col for col in dataset.column_names if col != \"prompt\"])\n",
    "    # dataset = dataset.shuffle(seed=42).select(range(min(1000, len(dataset))))  # Ensure we get up to 1000 samples\n",
    "    print(\"\\033[92m Save number of data: \\033[0m\", len(dataset))\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset.to_list(), f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Number of data after filtering: \u001b[0m 339\n",
      "\u001b[92m Save number of data: \u001b[0m 339\n"
     ]
    }
   ],
   "source": [
    "dataset = get_markdown_structure_data(\"yahma/alpaca-cleaned\", \"train\", \"alpaca-markdown.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<instruction>\n",
      "Refactor this code and add comments.def factorialize(num):\n",
      "  factorial = 1\n",
      "  for i in range(1, num):\n",
      "    factorial *= i\n",
      "  \n",
      "  return factorial\n",
      "</instruction>\n",
      "<response>\n",
      "```\n",
      "# This is a function that calculates the factorial of a given number\n",
      "def factorialize(num):\n",
      "  # Set the variable 'factorial' to 1\n",
      "  factorial = 1\n",
      "  # Iterate from 1 to 'num' using the range function\n",
      "  for i in range(1, num):\n",
      "    # Multiply the 'factorial' variable by the current number in the iteration\n",
      "    factorial *= i\n",
      "  # Return the final value of 'factorial'\n",
      "  return factorial\n",
      "```\n",
      "</response>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['prompt'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a meticulous organizational assistant specialized in structuring instruction-response pairs into a standardized markdown format. Please carefully process the input according to the following specifications:\n",
      "\n",
      "---\n",
      "tags:\n",
      "  - {general_tag} {general_tag}/{sub_tag}\n",
      "---\n",
      "# Instruction\n",
      "[The original instruction text]\n",
      "\n",
      "# Summary\n",
      "[A brief yet comprehensive summary of the response]\n",
      "\n",
      "## Details\n",
      "[The original response content]\n",
      "\n",
      "Here are Processing Guidelines:\n",
      "- The `tags` section consists of pairs of general tags and sub tags in the following format:  `{general_tag} {general_tag}/{sub_tag}`. For example: `environment environment/renewable_energy`.\n",
      "- Keep the heaidng levels in the original response and adjust heading levels as needed to maintain proper hierarchy and avoid jumping heading levels.\n",
      "\n",
      "The instructions and responses are enclosed within `<instruction>` and `<response>` XML tags, respectively. Please process the following instruction-response pairs with precision and attention to structural integrity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['prompt'][0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data without markdown heading level struture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from utils.sys_prompts import IT_SYS_PROMPT as SYSTEM_PROMPT\n",
    "import random\n",
    "\n",
    "INSTRUCTION_RESPONSE_FORMAT = \"\"\"\\\n",
    "<instruction>\n",
    "{instruction}\n",
    "</instruction>\n",
    "<response>\n",
    "{response}\n",
    "</response>\n",
    "\"\"\"\n",
    "\n",
    "def get_naive_data(url, split=\"train\", output_file=\"dataset.json\", number_data=7000):\n",
    "    dataset = load_dataset(url, split=split)\n",
    "    # since we want to emphasize the logical hierarchy\n",
    "    def check_structure_markdown(text):\n",
    "        structure_markdown_regrex = r\"^#{1,6} .*$\"\n",
    "        res = re.findall(structure_markdown_regrex, text[\"output\"], re.MULTILINE)\n",
    "        if len(res) > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def check_length(text):\n",
    "        length = len(text[\"output\"])\n",
    "        if  (length > 50) and (length < 2000):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    dataset = dataset.filter(lambda x: (not check_structure_markdown(x)) and check_length(x))\n",
    "    print(\"\\033[92m Number of data after filtering: \\033[0m\", len(dataset))\n",
    "    \n",
    "    def formatting_prompts_func(examples):\n",
    "        instruction = examples[\"instruction\"]\n",
    "        input       = examples[\"input\"]\n",
    "        output      = examples[\"output\"]\n",
    "        return {\n",
    "            'prompt': [\n",
    "                {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "                # few-shot\n",
    "                # {'role': 'user', 'content': INSTRUCTION_RESPONSE_FORMAT.format(instruction=(fewshot_example[\"instruction\"]+fewshot_example[\"input\"]).strip(), response=fewshot_example['output'])},\n",
    "                # {'role': 'assistant', 'content': fewshot_response},\n",
    "                {'role': 'user', 'content': INSTRUCTION_RESPONSE_FORMAT.format(instruction=(instruction+input).strip(), response=output)}\n",
    "            ],\n",
    "            # 'answer': extract_hash_answer(output)\n",
    "        }\n",
    "    \n",
    "    dataset = dataset.map(formatting_prompts_func, batched=False)\n",
    "    dataset = dataset.remove_columns([col for col in dataset.column_names if col != \"prompt\"])\n",
    "    dataset = dataset.shuffle(seed=42).select(range(min(number_data, len(dataset))))  # Ensure we get up to 1000 samples\n",
    "    print(\"\\033[92m Save number of data: \\033[0m\", len(dataset))\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset.to_list(), f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Number of data after filtering: \u001b[0m 42776\n",
      "\u001b[92m Save number of data: \u001b[0m 5000\n"
     ]
    }
   ],
   "source": [
    "dataset = get_naive_data(\"yahma/alpaca-cleaned\", \"train\", \"alpaca-naive.json\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a meticulous organizational assistant specialized in structuring instruction-response pairs into a standardized markdown format. Please carefully process the input according to the following specifications:\n",
      "\n",
      "---\n",
      "tags:\n",
      "  - {broad_category} {broad_category}/{specific_topic}\n",
      "---\n",
      "# Instruction\n",
      "[The original instruction text]\n",
      "\n",
      "# Summary\n",
      "[A brief yet comprehensive summary of the response]\n",
      "\n",
      "## Details\n",
      "[The full response content]\n",
      "• Adjust heading levels as needed to maintain proper hierarchy and avoid jumping heading levels.\n",
      "\n",
      "The instructions and responses are enclosed within `<instruction>` and `<response>` XML tags, respectively. Please process the following instruction-response pairs with precision and attention to structural integrity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"You are a meticulous organizational assistant specialized in structuring instruction-response pairs into a standardized markdown format. Please carefully process the input according to the following specifications:\\n\\n---\\ntags:\\n  - {broad_category} {broad_category}/{specific_topic}\\n---\\n# Instruction\\n[The original instruction text]\\n\\n# Summary\\n[A brief yet comprehensive summary of the response]\\n\\n## Details\\n[The full response content]\\n• Adjust heading levels as needed to maintain proper hierarchy and avoid jumping heading levels.\\n\\nThe instructions and responses are enclosed within `<instruction>` and `<response>` XML tags, respectively. Please process the following instruction-response pairs with precision and attention to structural integrity.\\n\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frugal-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
